{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module 11: Cutting-Edge AI Research**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise-1**\n",
    "\n",
    "**Title:** Federated Learning with Hybrid Symbolic-Neural Models\n",
    "\n",
    "**Problem Statement:**\n",
    "The goal is to demonstrate the implementation of a hybrid model that integrates symbolic rules (like logical operations) with a neural network-based model. This approach showcases how federated learning can be utilized where centralized data is unavailable, leveraging a combination of local data and shared neural network models.\n",
    "\n",
    "**Steps to Follow:**\n",
    "\n",
    "**1.\tDefine Symbolic Rules:** Implement symbolic rules (e.g., logical AND operation) as functions that can be integrated into a hybrid model.\n",
    "\n",
    "**2.\tCreate Neural Network Model:** Define a neural network model using TensorFlow/Keras to process input data.\n",
    "\n",
    "**3.\tImplement Hybrid Model:** Construct a hybrid model class (HybridModel) that encapsulates both symbolic rules and the neural network model. This class should include methods to predict using symbolic rules, the neural network, and a combined prediction mechanism.\n",
    "\n",
    "**4.\tGenerate Sample Data:** Generate sample data that corresponds to the logical AND operation for demonstration purposes.\n",
    "\n",
    "**5.\tTrain Neural Network Model:** Compile and train the neural network model using the generated sample data.\n",
    "\n",
    "**6.\tInstantiate Hybrid Model:** Create an instance of the HybridModel class, initialized with the trained neural network model.\n",
    "\n",
    "**7.\tMake Predictions:** Use the hybrid model to make predictions on the sample data, combining symbolic and neural network-based predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 0.7030\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6955\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6882\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6810\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6741\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6676\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6612\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6548\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6485\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6423\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Input: [0, 0] Prediction: 0.14467410743236542\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Input: [0, 1] Prediction: 0.13602737188339234\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Input: [1, 0] Prediction: 0.13811112642288206\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Input: [1, 1] Prediction: 0.8540563941001892\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define symbolic rules (example rules for logical AND operation)\n",
    "def logical_and(x, y):\n",
    "    return x and y\n",
    "\n",
    "# Define neural network-based model\n",
    "def create_neural_network_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Dense(64, activation='relu')(inputs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)  # Output a probability for binary classification\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define hybrid model integrating symbolic rules with neural network\n",
    "class HybridModel:\n",
    "    def __init__(self, neural_network_model):\n",
    "        self.neural_network_model = neural_network_model\n",
    "\n",
    "    def predict_with_symbolic_rules(self, inputs):\n",
    "        # Unpack inputs assuming it's a list of two elements\n",
    "        x, y = inputs\n",
    "        # Apply symbolic rules (logical AND operation) as an additional constraint\n",
    "        symbolic_output = logical_and(x, y)\n",
    "        return symbolic_output\n",
    "\n",
    "    def predict_with_neural_network(self, inputs):\n",
    "        # Use neural network-based model to predict\n",
    "        inputs = tf.convert_to_tensor([inputs])  # Convert inputs to tensor\n",
    "        neural_network_output = self.neural_network_model.predict(inputs)\n",
    "        return neural_network_output[0][0]  # Return the scalar prediction\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # Combine symbolic reasoning with neural network predictions\n",
    "        symbolic_prediction = self.predict_with_symbolic_rules(inputs)\n",
    "        neural_network_prediction = self.predict_with_neural_network(inputs)\n",
    "        # Combine predictions using a weighted average (can be adjusted based on application)\n",
    "        combined_prediction = 0.7 * symbolic_prediction + 0.3 * neural_network_prediction\n",
    "        return combined_prediction\n",
    "\n",
    "# Example usage\n",
    "# Generate some sample data for logical AND operation\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "targets = [logical_and(x[0], x[1]) for x in inputs]\n",
    "\n",
    "# Create and compile the neural network-based model\n",
    "neural_network_model = create_neural_network_model(input_shape=(2,))\n",
    "neural_network_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the neural network-based model\n",
    "neural_network_model.fit(inputs, targets, epochs=10)\n",
    "\n",
    "# Create the hybrid model\n",
    "hybrid_model = HybridModel(neural_network_model)\n",
    "\n",
    "# Make predictions using the hybrid model\n",
    "for input_data in inputs:\n",
    "    prediction = hybrid_model.predict(input_data)\n",
    "    print(\"Input:\", input_data, \"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "**1.\tSymbolic Rules and Neural Network Integration:** The HybridModel class integrates symbolic rules (logical AND) with a neural network model. It uses symbolic reasoning as an additional constraint and combines it with neural network predictions using a weighted average approach.\n",
    "\n",
    "**2.\tTraining and Prediction:** The neural network model is trained on the sample data (inputs and targets) for the logical AND operation. The HybridModel instance then makes predictions on each input data point, demonstrating the combined approach of symbolic reasoning and neural network predictions.\n",
    "\n",
    "\n",
    "This approach exemplifies how federated learning techniques can be employed in scenarios where symbolic rules and local data influence model predictions, offering flexibility and interpretability in machine learning applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise-2**\n",
    "\n",
    "**Title:** Implementing and Evaluating a Few-Shot Learning Model using a Convolutional Neural Network (CNN)\n",
    "\n",
    "**Problem Statement:**\n",
    "Few-shot learning aims to enable a model to recognize new classes with very few training examples. In this implementation, we use a Convolutional Neural Network (CNN) based on ResNet-18 to perform few-shot classification. We generate synthetic data for support and query sets across multiple classes and evaluate the model's performance on a separate test set. The trained model is saved for future use or deployment.\n",
    "\n",
    "**Steps to Follow:**\n",
    "\n",
    "1.\tData Preparation:\n",
    "\n",
    "    a.\tGenerate synthetic data for the support set, query set, and test set.\n",
    "\n",
    "    b.\tApply necessary transformations to the data.\n",
    "\n",
    "2.\tDefine the Dataset Class:\n",
    "\n",
    "    a.\tCreate a custom dataset class to handle the data and apply transformations.\n",
    "\n",
    "3.\tDefine the Few-Shot Learning Model:\n",
    "\n",
    "    a.\tUse a pretrained ResNet-18 model and modify its final layer to match the number of classes.\n",
    "\n",
    "4.\tTrain the Model:\n",
    "\n",
    "    a.\tTrain the model using the support and query sets.\n",
    "\n",
    "    b.\tCompute the loss and update the model parameters.\n",
    "\n",
    "5.\tEvaluate the Model:\n",
    "\n",
    "    a.\tEvaluate the trained model on a separate test set.\n",
    "\n",
    "    b.\tCalculate and display the test loss and accuracy.\n",
    "\n",
    "6.\tSave the Model:\n",
    "\n",
    "    a.\tSave the trained model for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.6576904773712158\n",
      "Epoch [2/10], Loss: 1.682487463951111\n",
      "Epoch [3/10], Loss: 1.6930868864059447\n",
      "Epoch [4/10], Loss: 1.714703917503357\n",
      "Epoch [5/10], Loss: 1.6887953281402588\n",
      "Epoch [6/10], Loss: 1.6653315782546998\n",
      "Epoch [7/10], Loss: 1.6665464162826538\n",
      "Epoch [8/10], Loss: 1.6636360168457032\n",
      "Epoch [9/10], Loss: 1.6761986494064331\n",
      "Epoch [10/10], Loss: 1.6884828805923462\n",
      "Test Loss: 1.8628565311431884\n",
      "Test Accuracy: 12.0%\n",
      "Model saved to few_shot_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Define the Few-Shot Learning Dataset\n",
    "class FewShotDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample, label = self.data[idx], self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n",
    "\n",
    "# Define the Few-Shot Learning Model\n",
    "class FewShotModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FewShotModel, self).__init__()\n",
    "        self.base_model = torchvision.models.resnet18(pretrained=True)\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Prepare the Few-Shot Learning Data\n",
    "num_classes = 5\n",
    "num_examples_per_class = 5\n",
    "support_set_size = num_classes * num_examples_per_class\n",
    "query_set_size = num_classes * num_examples_per_class\n",
    "\n",
    "# Generate random data for the support set and query set (replace with your own dataset)\n",
    "support_data = torch.randn(support_set_size, 3, 224, 224)  # Random RGB images (224x224)\n",
    "query_data = torch.randn(query_set_size, 3, 224, 224)  # Random RGB images (224x224)\n",
    "support_labels = torch.tensor(np.repeat(np.arange(num_classes), num_examples_per_class))\n",
    "query_labels = torch.tensor(np.repeat(np.arange(num_classes), num_examples_per_class))\n",
    "\n",
    "# Generate random data for the test set (replace with your own dataset)\n",
    "test_data = torch.randn(query_set_size, 3, 224, 224)  # Random RGB images (224x224)\n",
    "test_labels = torch.tensor(np.repeat(np.arange(num_classes), num_examples_per_class))\n",
    "\n",
    "# Define transformations for data augmentation (optional)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create Few-Shot Learning Datasets and DataLoaders\n",
    "support_dataset = FewShotDataset(support_data, support_labels, transform=transform)\n",
    "query_dataset = FewShotDataset(query_data, query_labels, transform=transform)\n",
    "test_dataset = FewShotDataset(test_data, test_labels, transform=transform)\n",
    "\n",
    "support_loader = DataLoader(support_dataset, batch_size=num_examples_per_class, shuffle=True)\n",
    "query_loader = DataLoader(query_dataset, batch_size=num_examples_per_class, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=num_examples_per_class, shuffle=True)\n",
    "\n",
    "# Define Few-Shot Learning Model and Optimizer\n",
    "model = FewShotModel(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the Few-Shot Learning Model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for support_batch, query_batch in zip(support_loader, query_loader):\n",
    "        support_inputs, support_labels = support_batch\n",
    "        query_inputs, query_labels = query_batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass (using support set for adaptation)\n",
    "        support_outputs = model(support_inputs)\n",
    "        support_loss = criterion(support_outputs, support_labels)\n",
    "        support_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate on the query set\n",
    "        with torch.no_grad():\n",
    "            query_outputs = model(query_inputs)\n",
    "            query_loss = criterion(query_outputs, query_labels)\n",
    "            running_loss += query_loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(query_loader)}')\n",
    "\n",
    "# Evaluate the Few-Shot Learning Model on Test Set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        loss = criterion(test_outputs, test_labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(test_outputs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "print(f'Test Loss: {test_loss / len(test_loader)}')\n",
    "print(f'Test Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# Save the Few-Shot Learning Model\n",
    "model_path = 'few_shot_model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f'Model saved to {model_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of Steps:**\n",
    "\n",
    "1.\tData Preparation:\n",
    "\n",
    "    a.\tGenerated synthetic data for support, query, and test sets.\n",
    "\n",
    "    b.\tApplied transformations for resizing and normalization.\n",
    "\n",
    "2.\tDataset Class:\n",
    "\n",
    "    a.\tCreated a FewShotDataset class to handle the data and apply transformations.\n",
    "\n",
    "3.\tFew-Shot Learning Model:\n",
    "\n",
    "    a.\tDefined a model using a pretrained ResNet-18 and modified its final layer.\n",
    "\n",
    "4.\tTraining:\n",
    "\n",
    "    a.\tTrained the model using support and query sets, computed loss, and updated model parameters.\n",
    "\n",
    "5.\tEvaluation:\n",
    "\n",
    "    a.\tEvaluated the model on a separate test set, computed test loss, and accuracy.\n",
    "\n",
    "6.\tSaving:\n",
    "\n",
    "    a.\tSaved the trained model using torch.save for future use or deployment.\n",
    "    This script covers the entire process from data preparation to model training, evaluation, and saving.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
